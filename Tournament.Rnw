\documentclass{tufte-book}
\usepackage{graphicx}  % werken met figuren
\usepackage{gensymb} % werken met wetenschappelijke eenheden\usepackage{geometry}
\usepackage{changepage} % http://ctan.org/pkg/changepage
\usepackage[dutch,british]{babel} % instelling van de taal (woordsplitsing, spellingscontrole)
\usepackage[parfill]{parskip} % Paragrafen gescheiden door witte lijn en geen inspringing
\usepackage[font=small,skip=3pt]{caption} % Minder ruimte tussen figuur/table en ondertitel. Ondertitel klein
\usepackage{capt-of}
\usepackage{indentfirst}
\setlength{\parindent}{0.7cm}
\usepackage{enumitem} % Laat enumerate werken met letters
\usepackage{url}
\usepackage{lipsum}
\setkeys{Gin}{width=\linewidth,totalheight=\textheight,keepaspectratio}
% Prints a trailing space in a smart way.
\usepackage{xspace}
\usepackage{hyperref}
\usepackage{amsmath}

\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% Alter some LaTeX defaults for better treatment of figures:
% See p.105 of "TeX Unbound" for suggested values.
% See pp. 199-200 of Lamport's "LaTeX" book for details.
%   General parameters, for ALL pages:
    \renewcommand{\topfraction}{0.9}	% max fraction of floats at top
    \renewcommand{\bottomfraction}{0.9}	% max fraction of floats at bottom
%   Parameters for TEXT pages (not float pages):
    \setcounter{topnumber}{2}
    \setcounter{bottomnumber}{2}
    \setcounter{totalnumber}{4}     % 2 may work better
    \renewcommand{\textfraction}{0.1}	% allow minimal text w. figs
%   Parameters for FLOAT pages (not text pages):
    \renewcommand{\floatpagefraction}{0.8}	% require fuller float pages
% N.B.: floatpagefraction MUST be less than topfraction !!
\setcounter{secnumdepth}{3}

\newcommand{\tthdump}[1]{#1}

\newcommand{\openepigraph}[2]{
  \begin{fullwidth}
  \sffamily\large
    \begin{doublespace}
      \noindent\allcaps{#1}\\ % epigraph
      \noindent\allcaps{#2} % author
    \end{doublespace}
  \end{fullwidth}
}


\usepackage{makeidx}
\makeindex

\title{Notes on " A Prediction Tournament Paradox" (prof. David J. Aldous)}
\author{Jan Trommelmans}

\begin{document}
\SweaveOpts{concordance=TRUE,prefix.string=Tour}
\setkeys{Gin}{width=1.1\marginparwidth} %% Sweave

<<echo=FALSE>>=
library(tidyverse)
library(gridExtra)
@

% Setting the ggplot theme:
<<echo=FALSE>>=
JT.theme <- theme(panel.border = element_rect(fill = NA, colour = "gray10"),
                  panel.background = element_blank(),
                  panel.grid.major = element_line(colour = "gray85"),
                  panel.grid.minor = element_line(colour = "gray85"),
                  panel.grid.major.x = element_line(colour = "gray85"),
                  axis.text = element_text(size = 8 , face = "bold"),
                  axis.title = element_text(size = 9 , face = "bold"),
                  plot.title = element_text(size = 12 , face = "bold"),
                  strip.text = element_text(size = 8 , face = "bold"),
                  strip.background = element_rect(colour = "black"),
                  legend.text = element_text(size = 8),
                  legend.title = element_text(size = 9 , face = "bold"),
                  legend.background = element_rect(fill = "white"),
                  legend.key = element_rect(fill = "white"))
@

% Functions

\frontmatter
\chapter*{Notes on David J. Aldous's paper: \qquad \qquad \qquad \qquad \qquad \quad" A Prediction Tournament Paradox}
\chaptermark*{Jan Trommelmans}

\chapter*{Introduction}
In his paper "A Prediction Tournament Paradox", David J. Aldous\footnote{A Prediction Tournament Paradox, David J. Aldous, Department of Statistics, U.C. Berkeley CA 94720-3860, May 26, 2018} shows that in a contest with many tournaments, each dealing with 100 questions, the most accurate forecasters do not necessarily score the highest number of wins when the number of forecasters is large.

These notes try to explain the scoring methods that prof. Aldous uses, how the simulations are done and how to interpret the figures and tables in his paper. His simulations are reconstructed using the programming language R. Some extra figures are included in the hope of clarifiying the different steps in the paper. At the end an alternative model is proposed.

From these notes I tend to conclude that the paradox is the result of the special position that is taken by what is called the \emph{Perfect Forecaster}. Once we recognise that in reality this forecaster does not exist, and therefore should not be included in our simulations, the paradox as such disappears. However, the paper convincingly shows that, although the better forecasters will win, they do so much less frequently than our intuition suggests. The main cause for this is the fact that the chance that determines the outcome of each question (a Bernouilli proces), dominates the scene and substantially reduces the effect of the ability of the players. Luck and skill are combined, and luck is powerful in these kinds of situations.

\mainmatter
\chapter{Scores}

\section{Forecasting and calculating the score}

\subsection{Probabilities of events and choices made by the forecaster}
A \emph{tournament} consists of a number of questions. To keep things uncluttered let us start with 10 questions. All these questions have an, unknown, probability $p_{i} \quad (i=1 \ldots 10)$ that an event will actually happen before or on a specific date. Let's assume that some questions deal with events that are very unlikely (low $p_{i}$), some are a toss up, and some are highly likely (high $p_{i}$). A forecaster\sidenote[][-2cm]{To avoid to write every time ''he/she", from now on I will assume the forecaster to be female} proposes for each question a probability $q_{i} \quad i=1 \ldots 10$ that the event will occur. The choices she makes depend of course on the knowledge she has on the subject matter of the question in case. The situation before the expiry date looks something like Table~\ref{table:before}\sidenote[][-2.5cm]{The questions are ordered from very unlikely to very likely}:

\medskip

\begin{margintable}[-2cm]
\caption{Before end of tournament}
\centering
\begin{tabular}{ c | c | c | }
  question & $p_{i}$ & $q_{i}$ \\
  \hline
  1 & 0.05 & 0.14 \\
  2 & 0.15 & 0.06 \\
  3 & 0.25 & 0.19 \\
  4 & 0.35 & 0.43 \\
  5 & 0.45 & 0.23 \\
  6 & 0.55 & 0.71 \\
  7 & 0.65 & 0.66 \\
  8 & 0.75 & 0.81 \\
  9 & 0.85 & 0.69 \\
  10 & 0.95 & 1
\end{tabular}
\label{table:before}
\end{margintable}

\subsection{Situation at the end of the tournament}
\label{subsec:expiry}
When the expiry date arrives, things change. Either the event has happened (result=1) or it has not (result=0). For events  with a low probability $p_{i}$ most of the time the result will be 0. But there can be surprises and a low probability event can in fact occur (see question 2 in Table~\ref{table:after}). Idem for events with a high probability: every now and then they do not materialise (see question 8 in Table~\ref{table:after}). Events with medium probabilities will be even more prone to chance. For each question a score is calculates using the formula:
\begin{equation}
score_{i}=(result_{i} - q_{i})^2
\end{equation}

The total score is then:
\begin{equation}
score_{total}=\sum_{i=1}^{i=n}score_{i}=\sum_{i=1}^{i=n}\left( result_{i} - q_{i} \right)^{2} \quad \text{n= number of questions}
\end{equation}

\medskip

\begin{margintable}[-6cm]
\caption{Situation at end date of tournament}
\centering
\begin{tabular}{ c | c | c || c | c}
  question & $p_{i}$ & $q_{i}$ & $result_{i}$ & $score_{i}$\\
  \hline
  1 & 0.05 & 0.14 & 0 & $0.14^{2}=0.0196$\\
  2 & 0.15 & 0.06 & 1 & $0.94^{2}=0.8836$\\
  3 & 0.25 & 0.19 & 0 & $0.19^{2}=0.0361$\\
  4 & 0.35 & 0.43 & 0 & $0.43^{2}=0.1849$\\
  5 & 0.45 & 0.23 & 1 & $0.77^{2}=0.5929$\\
  6 & 0.55 & 0.71 & 1 & $0.29^{2}=0.0841$\\
  7 & 0.65 & 0.66 & 0 & $0.66^{2}=0.4356$\\
  8 & 0.75 & 0.81 & 0 & $0.81^{2}=0.6561$\\
  9 & 0.85 & 0.69 & 1 & $0.31^{2}=0.0961$\\
  10 & 0.95 & 1 & 1 & $0^{2}=0$\\
  \hline
   &  &  &  & $2.989$
\end{tabular}
\label{table:after}
\end{margintable}

\medskip

\newthought{It is very important to realise} that if we run a second tournament with 10 questions with the same probabilities $p_{i}$, and the forecaster would give exactly the same answers for the probabilities $q_{i}$, the total score could be different! This is because of the intermediate step where at the expiry date of an event it changes from a \emph{probability} $p_{i}$ into a \emph{reality} $result_{i}$: it happens or it does not happen. An event with probability 30\% could for example ''not happen" in the first tournament, but ''happen" in the second tournament. So it could be that in tournament 2 we get the following results (Table~\ref{table:tournament2}) (note the change in the result for questions 2 and 8):

\medskip

\begin{margintable}[-4cm]
\caption{Tournament 2}
\centering
\begin{tabular}{ c | c | c || c | c}
  question & $p_{i}$ & $q_{i}$ & $result_{i}$ & $score_{i}$\\
  \hline
  1 & 0.05 & 0.14 & 0 & $0.14^{2}=0.0196$\\
  2 & 0.15 & 0.06 & \textbf{0} & $0.06^{2}=0.0036$\\
  3 & 0.25 & 0.19 & 0 & $0.19^{2}=0.0361$\\
  4 & 0.35 & 0.43 & 0 & $0.43^{2}=0.1849$\\
  5 & 0.45 & 0.23 & 1 & $0.77^{2}=0.5929$\\
  6 & 0.55 & 0.71 & 1 & $0.29^{2}=0.0841$\\
  7 & 0.65 & 0.66 & 0 & $0.66^{2}=0.4356$\\
  8 & 0.75 & 0.81 & \textbf{1} & $0.19^{2}=0.0361$\\
  9 & 0.85 & 0.69 & 1 & $0.31^{2}=0.0961$\\
  10 & 0.95 & 1 & 1 & $0^{2}=0$\\
  \hline
   &  &  &  & $1.489$
\end{tabular}
\label{table:tournament2}
\end{margintable}

\medskip

The same forecaster, giving the same predictions based on her know-ledge about questions with the same probabilities, will get a different score because there is an uncontrollable factor ''chance" that makes the event happen on one occasion but not on another. From this it follows that if we run 1000 tournaments with 100 questions with the same actual probabilities ($p_{i}$), and the forecaster gives the same estimate ($q_{i}$) for the probability that the event will occur, we will get 1000 slightly different total scores. In short: the total score will show some variation around an average value of the total score.

\section{Average (or Expected) value of the score}

When we have a variable that depends on chance (such as the total score) it can have different values with different probabilities. In our case the score on question $i$ can have two values:
\begin{equation}
  \begin{split}
  \text{if the event occurs:} & \quad  score_{i}=(1-q_{i})^2 \\
  \text{if the event does not occur:} & \quad score_{i}=(q_{i})^2
  \end{split}
\end{equation}

The probablities that the event occurs or not are:
\begin{equation}
  \begin{split}
  \text{probability that the event occurs=} & p_{i} \\
  \text{probability that the event does not occur=} & (1-p_{i})
  \end{split}
\end{equation}

You can find the \emph{Expected Value} of the score by multiplying the possible scores with their probability and adding the results:
\begin{equation}
  \begin{split}
    E(score_{i})&=(1-q_{i})^2(p_{i}) + (q_{i})^2(1-p_{i}) \\
    &= (p_{i} - 2p_{i}q_{i} + p_{i}q_{i}^2) + (q_{i}^{2}-p_{i}q_{i}^{2}) \\
    &= p_{i} - 2p_{i}q_{i}+q_{i}^{2} = p_{i} - p_{i}^{2} + p_{i}^{2} - 2p_{i}q_{i}+q_{i}^{2} \\
    &= p_{i}(1-p_{i}) + (q_{i}-p_{i})^{2}
  \end{split}
\end{equation}

The total average score is the sum of all the average question scores:
\begin{equation}
E(score_{total})=E(\sum_{i=1}^{i=n}score_{i})=\sum_{i=1}^{i=n}p_{i}(1-p_{i}) + \sum_{i=1}^{i=n}(q_{i}-p_{i})^{2}
\label{eq:meantotal}
\end{equation}

\chapter{A tale of three forecasters}

We are going to look at the scores of three different forecasters. Each forecaster will take part in N tournaments\sidenote{N can be very large e.g. 10.000. It's just the computer doing all the work}. Each tournament has 100 question: 10 questions about events with a probability of occurence $p=0.05$, 10 questions with probability of occurence $p=0.15$, and so on in steps of $0.10$, until the last set of 10 questions about events with probability of occurence $p=0.95$.

\section{The Perfect Forecaster}
This forecaster is faultless: for every question she ''knows" the exact probability. So for every question her choice $q_{i}$ of the probability of occurence ot the event is exactly equal to $p_{i}$. We can calculate the expected value of the total score of the Perfect Forecaster using Equation~\ref{eq:meantotal}. The second term in this equation is 0 because the Perfect Forecaster always chooses $q_{i}=p_{i}$:
\begin{equation}
\label{eq:perfect}
E(S_{perfect})=\sum_{i=1}^{i=n}p_{i}(1-p_{i})
\end{equation}

The average score of the \emph{Perfect Forecaster} is fixed once we have chosen the values of $p_{i}$ and the number of questions $n$. In this example the average perfect score is $16.75$. As explained in \ref{subsec:expiry} the end scores for the different tournaments will lie around this average score (Figure~\ref{fig:Perfect}).

<<echo=FALSE>>=
Aldous <- TRUE
N <- 2000 # number of tournaments
n <- 100 # number of questions per tournament
prob.event <- seq(0.05, 0.95, by=0.1) # sequence of true probabilities
@

<<label=Perfect,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and randomly chosen probabilities q in range [0,1]
total_score_perfect <- data.frame(result=rep(0, N))
# defining the real probabilities for each question: 10 questions with prob=0.05; 10 with prob=0.15 and so on till prob=0.95
tour_run <- data.frame(p = rep(prob.event, n/10), q = 0, event=0)
# simulating N tournaments
for (i in (1:N)) {
  tour_run$q = tour_run$p # The perfect forecaster knows the true probabilities
  tour_run$event <- rbinom(n,1,tour_run$p)
  tour_run$question.score <- (tour_run$event - tour_run$q)^2
  total_score_perfect$result[i] <- sum(tour_run$question.score)
}
perfect_score <- sum(tour_run$p*(1-tour_run$p))
gem.result.perfect <- mean(total_score_perfect$result)
ggplot() +
  geom_histogram(data=total_score_perfect, aes(x = result, y = ..density..), 
                 binwidth=1, fill="lightblue", color="grey60", size=0.2) +
  geom_density(data=total_score_perfect, aes(x = result, y = ..density..)) +
  geom_vline(xintercept=perfect_score, color="red", size=0.8) +
  xlim(0, 50) +
  labs(title = paste("Distribution of total scores for", N, "tournaments"), 
       subtitle = "Perfect Forecaster",
       x = "total score", 
       y = "density") +
  JT.theme
@

\begin{marginfigure}[-7cm]
\centering
\includegraphics[width=200pt, height=200pt]{Tour-Perfect}
\caption{Perfect Forecaster}
\label{fig:Perfect}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\section{The Ignorant Forecaster}

The \emph{Ignorant Forecaster} has no insight at all in the matter and chooses for each question at random\sidenote{random uniform distribution within [0,1]} a probability $q_{i}$ in the range [0,1].

Her average total score is given by Equation~\ref{eq:meantotal}:
\begin{equation}
\label{eq:ignorant}
E(S_{ignorant})=\sum_{i=1}^{i=n}p_{i}(1-p_{i}) + \sum_{i=1}^{i=n}(q_{i}-p_{i})^{2} = \sum_{i=1}^{i=n}p_{i}(1-p_{i}) + n\sigma_{ignorant}^2
\end{equation}

Because the second term is always positive, the average total score of the Ignorant Forecaster will always be higher that the average score of the Perfect Forecaster.

<<label=Ignorant,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and randomly chosen probabilities q in range [0,1]
total_score_ignorant <- data.frame(result=rep(0,N))
# defining the real probabilities for each question: 10 questions with prob=0.05; 10 with prob=0.15 and so on till prob=0.95
tour_run <- data.frame(p = rep(prob.event, n/10), q = 0, event=0)
# simulating N tournaments
for (i in (1:N)) {
  tour_run$q = runif(n) # The ignorant forecaster just picks a value in the range [0,1]
  tour_run$event <- rbinom(n,1,tour_run$p)
  tour_run$question.score <- (tour_run$event - tour_run$q)^2
  total_score_ignorant$result[i] <- sum(tour_run$question.score)
}
gem.result.ignorant <- mean(total_score_ignorant$result)
ggplot(data=total_score_ignorant, aes(x = result, y = ..density..)) +
  geom_histogram(data=total_score_ignorant, aes(x = result, y = ..density..), 
                 binwidth=1, fill="lightblue", color="grey60", size=0.2) +
  geom_density(data=total_score_ignorant, aes(x = result, y = ..density..)) +
  geom_density(data=total_score_perfect, aes(x = result, y = ..density..), color="red", linetype=2, size=0.5 ) +
  geom_vline(xintercept=perfect_score, color="red", size=0.5) +
  geom_vline(xintercept=gem.result.ignorant, color="blue", size=0.8) +
  annotate("text", x= perfect_score, y= 0.04, label="Perfect", color="red") +
  annotate("text", x= perfect_score, y= 0.03, label="Forecaster", color="red") +
  annotate("text", x= gem.result.ignorant, y= 0.16, label="Ignorant", color="blue") +
  annotate("text", x= gem.result.ignorant, y= 0.15, label="Forecaster", color="blue") +
  xlim(0, 50) +
  labs(title = paste("Distribution of total scores for", N, "tournaments"), 
       subtitle = "Ignorant Forecaster",
       x = "total score", 
       y = "density") +
  JT.theme
@

\begin{marginfigure}
\centering
\includegraphics[width=200pt, height=200pt]{Tour-Ignorant}
\caption{Ignorant Forecaster}
\label{fig:Ignorant}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

As we can see (Figure~\ref{fig:Ignorant} there is a very slight overlap between the range of scores of the \emph{Perfect Forecaster} and the \emph{Ignorant Forecaster}. So it could happen that in some tournaments the worst possible forecaster, beats the best one! But it is very unlikely.

\section{A Realistic Forecaster}
\subsection{Model for a realistic forecaster}
The \emph{Realistic Forecaster} is someone who does not make a random choice of the probability within the whole range $[0,1]$ but, because of her ability, she will pick a value for $q_{i}$ that is closer to the real probability $p_{i}$. In his paper prof. Aldous proposes the following model\sidenote[][-1cm]{Simple model for predictions by contestant with RMS error $\sigma$}: a forecaster with ''error" $\sigma$ will choose for her probability $q_{i}$ either the value $(p_{i}-\sigma)$ or the value $(p_{i}+\sigma)$ with equal probability.\sidenote[][-0.5cm]{So there is a 50\% chance that $q_{i}=(p_{i}-\sigma)$ and a 50\% chance that $q_{i}=(p_{i}+\sigma)$}. If $q_{i}=(p_{i}-\sigma)<0$ $q_{i}$ will be set to 0. Idem when $q_{i}=(p_{i}+\sigma)>1$ we will set $q_{i}=1$.\sidenote{Other models are possible. For example: the \emph{Realistic Forecaster} could pick at random a probability $q_{i}$ in the range $[(p_{i}-\sigma),(p_{i}+\sigma)]$. Or we could use some normal distribution within this range. At the moment let us stick to prof. Aldous's model.}

<<label=Better,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
total_score_better <- data.frame(result=rep(0,N))
tour_run <- data.frame(p = rep(prob.event, n/10), q = 0)
sigma <- 0.4
# i is number of tournaments
for (i in (1:N)) {
  tour_run$lower.limit <- ifelse(tour_run$p - sigma < 0, 0, tour_run$p - sigma)
  tour_run$upper.limit <- ifelse(tour_run$p + sigma > 1, 1, tour_run$p + sigma)
# The Realistic Forecaster picks either [p-sigma] (50% chance) or [p+sigma] (50% chance) - (David J. Aldous)
# or
# picks a value in the range [p-sigma,p+sigma] - (J. Trommelmans)
#
# Switch between these two options by setting the variable Aldous to TRUE or FALSE
  if(Aldous==TRUE) { 
        tour_run$q <- ifelse(runif(n,tour_run$lower.limit,tour_run$upper.limit)<(tour_run$lower.limit+tour_run$upper.limit)/2, 
                              tour_run$lower.limit, 
                              tour_run$upper.limit)
  } else {
        tour_run$q <- runif(n, tour_run$lower.limit, tour_run$upper.limit)
}
  tour_run$event <- rbinom(n,1,tour_run$p)
  tour_run$question.score <- (tour_run$event - tour_run$q)^2
  total_score_better$result[i] <- sum(tour_run$question.score)
}
gem.result.better <- mean(total_score_better$result)
ggplot(data=total_score_better, aes(x = result, y = ..density..)) +
  geom_histogram(data=total_score_better, aes(x = result, y = ..density..), 
                 binwidth=1, fill="lightgreen", color="grey60", size=0.2) +
  geom_density(data=total_score_better, aes(x = result, y = ..density..)) +
  geom_density(data=total_score_perfect, aes(x = result, y = ..density..), color="red", linetype=2, size=0.5 ) +
  geom_density(data=total_score_ignorant, aes(x = result, y = ..density..), color="blue", linetype=2, size=0.5 ) +
  geom_vline(xintercept=perfect_score, color="red", size=0.5, linetype=2) +
  annotate("text", x= perfect_score, y= 0.21, label="Perfect", color="red") +
  annotate("text", x= perfect_score, y= 0.20, label="Forecaster", color="red") +
  annotate("text", x= gem.result.better, y= 0.19, label="Realistic", color="black") +
  annotate("text", x= gem.result.better, y= 0.18, label="Forecaster", color="black") +
  annotate("text", x= gem.result.ignorant, y= 0.15, label="Ignorant", color="blue") +
  annotate("text", x= gem.result.ignorant, y= 0.14, label="Forecaster", color="blue") +
  geom_vline(xintercept=gem.result.ignorant, color="blue", size=0.5, linetype=2) +
  geom_vline(xintercept=gem.result.better, color="green", size=0.5) +
  xlim(0, 50) +
  labs(title = paste("Distribution of scores for", N, "tournaments"), 
       subtitle = "Realistic Forecaster",
       x = "total score", 
       y = "density") +
  JT.theme
@

\begin{figure}
\centering
\includegraphics[width=200pt, height=200pt]{Tour-Better}
\caption{Realistic Forecaster}
\label{fig:Better}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{figure}

As we expected (Figures~\ref{fig:Better}), the scores of the \emph{Realistic Forecaster} lie between the scores of the \emph{Perfect Forecaster} and the \emph{Ignorant Forecaster}. There is considerable overlap between the three (Perfect, Ignorant and Realistic) forecasters. Sometimes the Realistic Forecaster wins from the \emph{Perfect Forecaster}, sometimes she loses to the \emph{Ignorant Forecaster}.

\subsection{Five forecasters with different abilities}
When there are five contestants with $\sigma$ values equal to $0, 0.1, 0.25, 0.5, 0.75$ we get Figure~\ref{fig:FiveContestants}. For large values of $\sigma$, for example $\sigma=0.5$ and $\sigma=0.75$ the scores are bad. They are even worse than the score of the \emph{Ignorant Forecaster}! The reason is that the model used by prof. Aldous, forces the forecaster to pick either $q_{i}=(p_{i}-\sigma)$ or $q_{i}=(p_{i}+\sigma)$. For large values of $\sigma$ this means that either the lower limit $q_{i}=0$ or the upper limit $q_{i}=1$ will be crossed, which means that $q_{i}$ has a 50\% chance of being one of the extreme values $0$ or $1$. This is worse than the situation of the \emph{Ignorant Forecaster} who can always pick a random number in the range $[0,1]$, and is not tied to the extreme values. 

% Five contestants
<<label=FiveContestants,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
nC <- 5 # number of contestants
sigma.range <- c(0, 0.1, 0.25, 0.5, 0.75)
tour <- data.frame(tournament = rep(seq(1:N), each=n*nC),
                   contestant = rep(rep(seq(1:nC), each=n), N),
                   question = rep(seq(1:n), N*nC),
                   p = rep(prob.event, N*nC*n/10),
                   event = 0)
tour$sigma <-sigma.range[tour$contestant]
tour$lower.limit <- ifelse(tour$p - tour$sigma < 0, 0, tour$p - tour$sigma)
tour$upper.limit <- ifelse(tour$p + tour$sigma > 1, 1, tour$p + tour$sigma)
if(Aldous==TRUE) { 
        tour$q <- ifelse(runif(n*nC*N,tour$lower.limit,tour$upper.limit)<(tour$lower.limit+tour$upper.limit)/2, 
                              tour$lower.limit, 
                              tour$upper.limit)
} else {
        tour$q <- runif(n*nC*N, tour$lower.limit, tour$upper.limit)
}
for (i in (1:N)) {
 tour$event[((i-1)*n*nC+ 1):(i*n*nC)] <- rep(rbinom(n,1,prob.event),nC)
}
tour$question.score <- (tour$event - tour$q)^2
tour %>% 
  group_by(tournament, contestant, sigma) %>% 
  summarise(score=sum(question.score)) -> tournament.table1
tournament.table2 <- tournament.table1[order(tournament.table1$tournament, tournament.table1$score),]
tournament.table2$win <- rep(c(1,rep(0,nC-1)),N)
tour %>% group_by(contestant, tournament) %>% summarise(som=sum(question.score)) -> tournament.table3
t1 <- tournament.table3 %>% filter(contestant==1)
t2 <- tournament.table3 %>% filter(contestant==2)
t3 <- tournament.table3 %>% filter(contestant==3)
t4 <- tournament.table3 %>% filter(contestant==4)
t5 <- tournament.table3 %>% filter(contestant==5)
ggplot() + 
  geom_density(data=t1, aes(x = som, y = ..density..), color="black", size=0.5) +
  geom_density(data=t2, aes(x = som, y = ..density..), color="blue", size=0.5) +
  geom_density(data=t3, aes(x = som, y = ..density..), color="green", size=0.5) +
  geom_density(data=t4, aes(x = som, y = ..density..), color="red", size=0.5) +
  geom_density(data=t5, aes(x = som, y = ..density..), color="chocolate1", size=0.5) +
  annotate("text", x= 16.75, y= 0.22, label="sigma=0", color="black") +
  annotate("text", x= 21, y= 0.20, label="0.10", color="blue") +
  annotate("text", x= 22, y= 0.16, label="0.25", color="green") +
  annotate("text", x= 32, y= 0.125, label="0.50", color="red") +
  annotate("text", x= 45, y= 0.095, label="0.75", color="chocolate1") +
  xlim(0,60) +
  labs(title = paste("Distribution of scores for", N, "tournaments"), 
       subtitle = "Five forecasters",
       x = "total score", 
       y = "density") +
  JT.theme
@

\begin{marginfigure}[-5cm]
\centering
\includegraphics[width=200pt, height=200pt]{Tour-FiveContestants}
\caption{Five contestants}
\label{fig:FiveContestants}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\chapter{Winning tournaments}

In his paper prof. Aldous looks at the number of tournaments that contestants with different abilities (different values of $\sigma$) win. It's all about winning: only first place counts.

\section{Tournaments with two contestants}
When comparing two contestants, we could look at their \emph{average total score} over many tournaments: the Contestant with the lowest average score is the better one. However, when we look at only one tournament, it could be that the (worse) Contestant with the higher average score still performs better than the (better) Contestant with the lower average score. This is of course due to the spread of the scores \emph{around} the average value. By luck, Contestant 2 could be to the left of her average, while Contestant 1 could be to the right of her average. This seems in accordance with our intuition: in a game where both skill and chance play a role, the better player wins most of the time, but not always. As the difference of ability increases, the probability for a win for the better player increases.

% Two contestants: method1

<<echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
percentage_win_C1 <- data.frame(matrix(0, ncol = 6, nrow = 6))
colnames(percentage_win_C1) <- as.character(seq(0.05, 0.3, by=0.05))
rownames(percentage_win_C1) <- as.character(seq(0, 0.25, by=0.05))
for (j in (1:6)) {
  for (k in (j:6)) {
total_score_contest <- data.frame(Contestant1=rep(0,N), Contestant2=0)
tour_run <- data.frame(p = rep(prob.event, n/10), 
                       q1 = 0, q2=0,
                       lower.limitC1=0, upper.limitC1=0, 
                       lower.limitC2=0, upper.limitC2=0,
                       event=0)
winC1 <- 0
winC2 <- 0
sigma_C1 <- (j-1)*0.05
sigma_C2 <- (k)*0.05
for (i in (1:N)) {
  tour_run$lower.limitC1 <- ifelse(tour_run$p - sigma_C1 < 0, 0, tour_run$p - sigma_C1)
  tour_run$upper.limitC1 <- ifelse(tour_run$p + sigma_C1 > 1, 1, tour_run$p + sigma_C1)
  tour_run$lower.limitC2 <- ifelse(tour_run$p - sigma_C2 < 0, 0, tour_run$p - sigma_C2)
  tour_run$upper.limitC2 <- ifelse(tour_run$p + sigma_C2 > 1, 1, tour_run$p + sigma_C2)
  if(Aldous==TRUE) { 
        tour_run$q1 <- ifelse(runif(n,tour_run$lower.limitC1,tour_run$upper.limitC1)<(tour_run$lower.limitC1+tour_run$upper.limitC1)/2, 
                              tour_run$lower.limitC1, 
                              tour_run$upper.limitC1)
  } else {
        tour_run$q1 <- runif(n, tour_run$lower.limitC1, tour_run$upper.limitC1)
}
  if(Aldous==TRUE) { 
        tour_run$q2 <- ifelse(runif(n,tour_run$lower.limitC2,tour_run$upper.limitC2)<(tour_run$lower.limitC2+tour_run$upper.limitC2)/2, 
                              tour_run$lower.limitC2, 
                              tour_run$upper.limitC2)
  } else {
        tour_run$q2 <- runif(n, tour_run$lower.limitC2, tour_run$upper.limitC2)
}
  tour_run$event <- rbinom(n,1,tour_run$p)
  tour_run$question.score.C1 <- (tour_run$event - tour_run$q1)^2
  tour_run$question.score.C2 <- (tour_run$event - tour_run$q2)^2
  total_score_contest$Contestant1[i] <- sum(tour_run$question.score.C1)
  total_score_contest$Contestant2[i] <- sum(tour_run$question.score.C2)
  if(total_score_contest$Contestant1[i] == total_score_contest$Contestant2[i]) {
    winC1 <- winC1 + 0.5
    winC2 <- winC2 + 0.5
  }
  ifelse(total_score_contest$Contestant1[i] < total_score_contest$Contestant2[i], winC1 <- winC1+1, winC2 <- winC2+1)
}
percentage_win_C1[j,k] <- format(round(100*winC1/N,2),nsmall=2)
  }
}
for (i in (2:6)) {
  for (j in (1:(i-1))) {
    percentage_win_C1[i,j] <- ""
  }
}
@
\smallskip
<<>>=
percentage_win_C1  
@
\medskip
The first column of Table ''Percentage\_win\_C1" shows the $\sigma$-factor for contestant 1. The first row shows the $\sigma$-factor for contestant 2. When the first contestant has $\sigma=0.05$ and the second contestant has $\sigma=0.2$ the table shows that contestant 1 will win 97.12\% of the tournaments. This table agrees with Figure 2 in prof. Aldous's paper\sidenote[][-1cm]{The differences are probably due to the number of tournaments N and the choice of the seed for the random number generator}.


\section{Tournaments with many contestants}

\subsection{Groups containing Perfect Forecasters}

When we have many contestants we expect the Realistic Forecaster to win more individual tournaments then the worse forecasters. Let us start with 10 forecasters, ranged from better to worse. This qualitative ranging is done by assigning to each forecaster a value for $\sigma$. In the first simulations we will let $\sigma$ take values from $0$ to $0.3$.The best forecaster (number 1) is the \emph{Perfect Forecaster} which means she has a $\sigma=0$. The worst forecaster (number 10) has a $\sigma=0.3$. Intermediat forecasters have intermediate values of $\sigma$. The result is given in Figure~\ref{fig:ten}. All seems as we would expect it: the best forecaster wins the most tournaments.
% 10 contestants
<<label=ten,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
nC <- 10 # number of contestants
sigma.min <- 0
sigma.max <- 0.3
tour <- data.frame(tournament = rep(seq(1:N), each=n*nC),
                   contestant = rep(rep(seq(1:nC), each=n), N),
                   question = rep(seq(1:n), N*nC),
                   p = rep(prob.event, N*nC*n/10),
                   event = 0)
tour$sigma <- sigma.min + (sigma.max - sigma.min)*(tour$contestant - 1)/(nC - 1)
tour$lower.limit <- ifelse(tour$p - tour$sigma < 0, 0, tour$p - tour$sigma)
tour$upper.limit <- ifelse(tour$p + tour$sigma > 1, 1, tour$p + tour$sigma)
if(Aldous==TRUE) { 
        tour$q <- ifelse(runif(n*nC*N,tour$lower.limit,tour$upper.limit)<(tour$lower.limit+tour$upper.limit)/2, 
                              tour$lower.limit, 
                              tour$upper.limit)
} else {
        tour$q <- runif(n*nC*N, tour$lower.limit, tour$upper.limit)
}
for (i in (1:N)) {
 tour$event[((i-1)*n*nC+ 1):(i*n*nC)] <- rep(rbinom(n,1,prob.event),nC)
}
tour$question.score <- (tour$event - tour$q)^2
tour %>% 
  group_by(tournament, contestant, sigma) %>% 
  summarise(score=sum(question.score)) -> tournament.table1
tournament.table2 <- tournament.table1[order(tournament.table1$tournament, tournament.table1$score),]
tournament.table2$win <- rep(c(1,rep(0,nC-1)),N)
tournament.table2 %>% group_by(contestant, sigma) %>% summarise(som=sum(win)) -> endscore
ggplot(data=endscore, aes(x=contestant, y=som)) + 
  geom_bar(stat="identity") +
  xlim(0,nC) +
  labs(title = "Tournament wins for each contestant", 
       subtitle = paste(nC,"forecasters","taking part in",N,"tournaments"),
       x = "contestant", 
       y = paste("number of wins in", N,"tournaments")) +
  JT.theme
@

\begin{marginfigure}[-2cm]
\centering
\includegraphics[width=200pt, height=200pt]{Tour-ten}
\caption{10 contestants}
\label{fig:ten}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}
\medskip
However: things change when the number of forecasters increases. Figure~\ref{fig:twenty} already shows another picture when we have twenty forecasters.

% 20 contestants
<<label=twenty,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
nC <- 20 # number of contestants
sigma.min <- 0
sigma.max <- 0.3
tour <- data.frame(tournament = rep(seq(1:N), each=n*nC),
                   contestant = rep(rep(seq(1:nC), each=n), N),
                   question = rep(seq(1:n), N*nC),
                   p = rep(prob.event, N*nC*n/10),
                   event = 0)
tour$sigma <- sigma.min + (sigma.max - sigma.min)*(tour$contestant - 1)/(nC - 1)
tour$lower.limit <- ifelse(tour$p - tour$sigma < 0, 0, tour$p - tour$sigma)
tour$upper.limit <- ifelse(tour$p + tour$sigma > 1, 1, tour$p + tour$sigma)
if(Aldous==TRUE) { 
        tour$q <- ifelse(runif(n*nC*N,tour$lower.limit,tour$upper.limit)<(tour$lower.limit+tour$upper.limit)/2, 
                              tour$lower.limit, 
                              tour$upper.limit)
} else {
        tour$q <- runif(n*nC*N, tour$lower.limit, tour$upper.limit)
}
for (i in (1:N)) {
 tour$event[((i-1)*n*nC+ 1):(i*n*nC)] <- rep(rbinom(n,1,prob.event),nC)
}
tour$question.score <- (tour$event - tour$q)^2
tour %>% 
  group_by(tournament, contestant, sigma) %>% 
  summarise(score=sum(question.score)) -> tournament.table1
tournament.table2 <- tournament.table1[order(tournament.table1$tournament, tournament.table1$score),]
tournament.table2$win <- rep(c(1,rep(0,nC-1)),N)
tournament.table2 %>% group_by(contestant, sigma) %>% summarise(som=sum(win)) -> endscore
ggplot(data=endscore, aes(x=contestant, y=som)) + 
  geom_bar(stat="identity") +
  xlim(0,nC) +
  labs(title = "Tournament wins for each contestant", 
       subtitle = paste(nC,"forecasters","taking part in",N,"tournaments"),
       x = "contestant", 
       y = paste("number of wins in", N,"tournaments")) +
  JT.theme
@

\begin{marginfigure}
\centering
\includegraphics[width=200pt, height=200pt]{Tour-twenty}
\caption{20 contestants}
\label{fig:twenty}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}
\medskip
When we increase the number of contestants further to 50 (Figure~\ref{fig:fifty}) the \emph{Paradox} becomes visible: the better forecasters are winning less and less tournaments! As prof. Aldous explains, this should not surprise us. The reason is that in these simulations we keep the total range for $\sigma$ constant between $0$ and $0.3$. The difference in the value of $\sigma$ between two sequential contestants is:
\begin{equation}
\delta_{\sigma}=\frac{(\sigma_{max}-\sigma_{min})}{(n_{C}-1)} \quad with \quad n_{C}=number \quad of \quad contestants
\end{equation}
As the number of contestants $n_{C}$ rises, the difference $\delta_{\sigma}$ will become smaller and smaller. With $\sigma_{max}=0.3$ and $\sigma_{min}=0$ the difference between two sequential contestants will be \Sexpr{round(0.3/9,3)} when there are 10 contestants, but only \Sexpr{round(0.3/49,3)} when there are 50 contestants. In the latter case the level of ability will be almost the same for two sequential contestants. When more and more contestants are added (up to 300 in prof. Aldous's paper), the distinction between two sequential contestants becomes almost indistinguishable.
% 50 contestants
<<label=fifty,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
nC <- 50 # number of contestants
sigma.min <- 0
sigma.max <- 0.3
tour <- data.frame(tournament = rep(seq(1:N), each=n*nC),
                   contestant = rep(rep(seq(1:nC), each=n), N),
                   question = rep(seq(1:n), N*nC),
                   p = rep(prob.event, N*nC*n/10),
                   event = 0)
tour$sigma <- sigma.min + (sigma.max - sigma.min)*(tour$contestant - 1)/(nC - 1)
tour$lower.limit <- ifelse(tour$p - tour$sigma < 0, 0, tour$p - tour$sigma)
tour$upper.limit <- ifelse(tour$p + tour$sigma > 1, 1, tour$p + tour$sigma)
if(Aldous==TRUE) { 
        tour$q <- ifelse(runif(n*nC*N,tour$lower.limit,tour$upper.limit)<(tour$lower.limit+tour$upper.limit)/2, 
                              tour$lower.limit, 
                              tour$upper.limit)
} else {
        tour$q <- runif(n*nC*N, tour$lower.limit, tour$upper.limit)
}
for (i in (1:N)) {
 tour$event[((i-1)*n*nC+ 1):(i*n*nC)] <- rep(rbinom(n,1,prob.event),nC)
}
tour$question.score <- (tour$event - tour$q)^2
tour %>% 
  group_by(tournament, contestant, sigma) %>% 
  summarise(score=sum(question.score)) -> tournament.table1
tournament.table2 <- tournament.table1[order(tournament.table1$tournament, tournament.table1$score),]
tournament.table2$win <- rep(c(1,rep(0,nC-1)),N)
tournament.table2 %>% group_by(contestant, sigma) %>% summarise(som=sum(win)) -> endscore
ggplot(data=endscore, aes(x=contestant, y=som)) + 
  geom_bar(stat="identity") +
  xlim(0,nC) +
  labs(title = "Tournament wins for each contestant", 
       subtitle = paste(nC,"forecasters","taking part in",N,"tournaments"),
       x = "contestant", 
       y = paste("number of wins in", N,"tournaments")) +
  JT.theme
@

\begin{marginfigure}
\centering
\includegraphics[width=200pt, height=200pt]{Tour-fifty}
\caption{50 contestants}
\label{fig:fifty}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\subsection{What is happening?}
The very good contestants have a very small value of $\sigma$ which means they will act like the \emph{Perfect Forecaster} and pick $q_{i}=p_{i}$. However, as we have seen in \ref{subsec:expiry}, the important thing is that the score is not based on the squared difference $(p_{i}-q_{i})^{2}$ but on the squared difference $(result_{i}-q_{i})^{2}$, where $result_{i}$ has the value $1$ or $0$ depending on the occurence of event $i$ (or not). The \emph{Perfect Forecaster} gets into trouble for those questions with a very low probability or a very high probability.

Let us take a question with a very low probability $p_{i}=0.05$. We get the following situation:
\begin{itemize}
  \item the \emph{Perfect Forecaster} chooses $q_{i}=p_{i}=0.05$ and her score will be
    \begin{enumerate}
      \item if the event does NOT occur: $score_{i}=(0-q_{i})^2=q_{i}^{2}=0.05^{2}=0.0025$
      \item if the event occurs: $score_{i}=(1-q_{i})^2=(1-0.05)^2=0.95^{2}=0.9025$
    \end{enumerate}
  \item a \emph{Realistic Forecaster} with $\sigma=0.1$ chooses either $q_{i}=(p_{i}-\sigma)=-0.05=0$ (50\% chance) or $q_{i}=(p_{i}+\sigma)=0.15$ (50\% chance)\sidenote{negative probabilities are impossible, so $q_{i}=-0.05$ is brought to $q_{i}=0$}. Her possible scores are:
    \begin{enumerate}
      \item if the event does NOT occur: $score_{i}=(0-q_{i})^2=0^{2}=0$ (50\%) or $score_{i}=(0-0.15)^2=0.15^{2}=0.0225$ (50\%)
      \item if the event occurs: $score_{i}=(1-q_{i})^2=1^{2}=1$ (50\%) or $score_{i}=(1-0.15)^2=0.85^{2}=0.7225$ (50\%)
    \end{enumerate}
\end{itemize}

On average the \emph{Perfect Forecaster} will have a score of $0.0025*0.95 + 0.9025*0.05=0.068875$ on a question with probability $p_{i}=0.05$. The \emph{Realistic Forecaster} with a $\sigma=0.1$ will get an average score of $\frac{0+0.0225}{2}*0.95 + \frac{1+0.7225}{2}*0.05=0.05375$, which is \emph{lower}!

When we redo this calculation for a \emph{Realistic Forecaster} with a $\sigma=0.3$ the average score of the \emph{Perfect Forecaster} on this question will remain the same ($0.068875$), but the average score of the \emph{Realistic Forecaster} will become $0.09375$, which is higher and worse.

This means that the choice of the model for the \emph{Perfect Forecaster} that she always picks $q_{i}=p_{i}$ give the \emph{Perfect Forecaster} a disadvantage for questions with low or high probability. The Paradox is the consequence of this choice.

The simple remedy for this, and one that is intuitively sounder, is to avoid these \emph{Perfect Forecasters} and to work only with \emph{Flawed Forecasters} which all have a $\sigma \neq 0$.

\subsection{Groups where all contestants are flawed}
Prof. Aldous's model is now that $\sigma_{min} > 0$. He puts $\sigma_{min}=0.15$ and keeps the range between the minimum and maximum value of $\sigma$ equal to $0.3$. This means that the maximum value is $\sigma_{max}=0.45$. The results can be seen in Figure~\ref{fig:fiftyflawed}: the better players start winning the most tournaments. The ''chance" element which occurs at the moment that the event materialises (or not) is however still strong, which means that poorer forecasters still win a considerable number of tournaments.

So, to all forecasters who have, or will, win tournaments: my congratulations. But do not forget that you enjoyed a good deal of luck, and you are welcome to it!

% 50 flawed contestants
<<label=fiftyflawed,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
nC <- 50 # number of contestants
sigma.min <- 0.15
sigma.max <- 0.45
tour <- data.frame(tournament = rep(seq(1:N), each=n*nC),
                   contestant = rep(rep(seq(1:nC), each=n), N),
                   question = rep(seq(1:n), N*nC),
                   p = rep(prob.event, N*nC*n/10),
                   event = 0)
tour$sigma <- sigma.min + (sigma.max - sigma.min)*(tour$contestant - 1)/(nC - 1)
tour$lower.limit <- ifelse(tour$p - tour$sigma < 0, 0, tour$p - tour$sigma)
tour$upper.limit <- ifelse(tour$p + tour$sigma > 1, 1, tour$p + tour$sigma)
if(Aldous==TRUE) { 
        tour$q <- ifelse(runif(n*nC*N,tour$lower.limit,tour$upper.limit)<(tour$lower.limit+tour$upper.limit)/2, 
                              tour$lower.limit, 
                              tour$upper.limit)
} else {
        tour$q <- runif(n*nC*N, tour$lower.limit, tour$upper.limit)
}
for (i in (1:N)) {
 tour$event[((i-1)*n*nC+ 1):(i*n*nC)] <- rep(rbinom(n,1,prob.event),nC)
}
tour$question.score <- (tour$event - tour$q)^2
tour %>% 
  group_by(tournament, contestant, sigma) %>% 
  summarise(score=sum(question.score)) -> tournament.table1
tournament.table2 <- tournament.table1[order(tournament.table1$tournament, tournament.table1$score),]
tournament.table2$win <- rep(c(1,rep(0,nC-1)),N)
tournament.table2 %>% group_by(contestant, sigma) %>% summarise(som=sum(win)) -> endscore
ggplot(data=endscore, aes(x=contestant, y=som)) + 
  geom_bar(stat="identity") +
  xlim(0,nC) +
  labs(title = "Tournament wins for each contestant", 
       subtitle = paste(nC,"forecasters","taking part in",N,"tournaments"),
       x = "contestant", 
       y = paste("number of wins in", N,"tournaments")) +
  JT.theme
@

\begin{marginfigure}[-5cm]
\centering
\includegraphics[width=200pt, height=200pt]{Tour-fiftyflawed}
\caption{50 flawed contestants}
\label{fig:fiftyflawed}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\chapter{Another model for the forecaster}

\section{Distribution of the total scores for different contestants}
A more gentle model for the \emph{Realistic Forecaster} is one that allows her to pick a random number in the range $[p_{i}-\sigma,p_{i}+\sigma]$ instead of having to pick either $(p_{i}-\sigma)$ or $(p_{i}+\sigma)$. In Figure~\ref{fig:FiveTRJ} we can see that the total scores of these forecasters, with different abilities (different values of $\sigma$) are better  than those in Figure~\ref{fig:FiveContestants}. This also means that the overlap between contestants increases and worse contestants are more likely to win.

<<echo=FALSE>>=
Aldous=FALSE #Pick model TRJ
@
% Five contestants model TRJ
<<label=FiveTRJ,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
nC <- 5 # number of contestants
sigma.range <- c(0, 0.1, 0.25, 0.5, 0.75)
tour <- data.frame(tournament = rep(seq(1:N), each=n*nC),
                   contestant = rep(rep(seq(1:nC), each=n), N),
                   question = rep(seq(1:n), N*nC),
                   p = rep(prob.event, N*nC*n/10),
                   event = 0)
tour$sigma <-sigma.range[tour$contestant]
tour$lower.limit <- ifelse(tour$p - tour$sigma < 0, 0, tour$p - tour$sigma)
tour$upper.limit <- ifelse(tour$p + tour$sigma > 1, 1, tour$p + tour$sigma)
if(Aldous==TRUE) { 
        tour$q <- ifelse(runif(n*nC*N,tour$lower.limit,tour$upper.limit)<(tour$lower.limit+tour$upper.limit)/2, 
                              tour$lower.limit, 
                              tour$upper.limit)
} else {
        tour$q <- runif(n*nC*N, tour$lower.limit, tour$upper.limit)
}
for (i in (1:N)) {
 tour$event[((i-1)*n*nC+ 1):(i*n*nC)] <- rep(rbinom(n,1,prob.event),nC)
}
tour$question.score <- (tour$event - tour$q)^2
tour %>% 
  group_by(tournament, contestant, sigma) %>% 
  summarise(score=sum(question.score)) -> tournament.table1
tournament.table2 <- tournament.table1[order(tournament.table1$tournament, tournament.table1$score),]
tournament.table2$win <- rep(c(1,rep(0,nC-1)),N)
tour %>% group_by(contestant, tournament) %>% summarise(som=sum(question.score)) -> tournament.table3
t1 <- tournament.table3 %>% filter(contestant==1)
t2 <- tournament.table3 %>% filter(contestant==2)
t3 <- tournament.table3 %>% filter(contestant==3)
t4 <- tournament.table3 %>% filter(contestant==4)
t5 <- tournament.table3 %>% filter(contestant==5)
ggplot() + 
  geom_density(data=t1, aes(x = som, y = ..density..), color="black", size=0.5) +
  geom_density(data=t2, aes(x = som, y = ..density..), color="blue", size=0.5) +
  geom_density(data=t3, aes(x = som, y = ..density..), color="green", size=0.5) +
  geom_density(data=t4, aes(x = som, y = ..density..), color="red", size=0.5) +
  geom_density(data=t5, aes(x = som, y = ..density..), color="chocolate1", size=0.5) +
  annotate("text", x= 16.75, y= 0.22, label="sigma=0", color="black") +
  annotate("text", x= 20.5, y= 0.20, label="0.10", color="blue") +
  annotate("text", x= 21, y= 0.185, label="0.25", color="green") +
  annotate("text", x= 24, y= 0.16, label="0.50", color="red") +
  annotate("text", x= 30, y= 0.15, label="0.75", color="chocolate1") +
  xlim(0,60) +
  labs(title = paste("Distribution of scores for", N, "tournaments"), 
       subtitle = "Five forecasters: uniform model in [p-sigma,p+sigma]",
       x = "total score", 
       y = "density") +
  JT.theme
@

\begin{marginfigure}[0cm]
\centering
\includegraphics[width=200pt, height=200pt]{Tour-FiveTRJ}
\caption{Five contestants with random pick in interval [p-sigma,p+sigma]}
\label{fig:FiveTRJ}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\section{Tournaments with 50 competitors}
\subsection{Groups with Perfect Forecasters}
As there is more overlap in this model, we expect that the situation for very good forecasters (close to the \emph{Perfect Forecaster}) will be even worse. And this is the case (Figure~\ref{fig:fiftyTRJ}). Tournament wins go more and more to average players.

% 50 contestants
<<label=fiftyTRJ,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
nC <- 50 # number of contestants
sigma.min <- 0
sigma.max <- 0.3
tour <- data.frame(tournament = rep(seq(1:N), each=n*nC),
                   contestant = rep(rep(seq(1:nC), each=n), N),
                   question = rep(seq(1:n), N*nC),
                   p = rep(prob.event, N*nC*n/10),
                   event = 0)
tour$sigma <- sigma.min + (sigma.max - sigma.min)*(tour$contestant - 1)/(nC - 1)
tour$lower.limit <- ifelse(tour$p - tour$sigma < 0, 0, tour$p - tour$sigma)
tour$upper.limit <- ifelse(tour$p + tour$sigma > 1, 1, tour$p + tour$sigma)
if(Aldous==TRUE) { 
        tour$q <- ifelse(runif(n*nC*N,tour$lower.limit,tour$upper.limit)<(tour$lower.limit+tour$upper.limit)/2, 
                              tour$lower.limit, 
                              tour$upper.limit)
} else {
        tour$q <- runif(n*nC*N, tour$lower.limit, tour$upper.limit)
}
for (i in (1:N)) {
 tour$event[((i-1)*n*nC+ 1):(i*n*nC)] <- rep(rbinom(n,1,prob.event),nC)
}
tour$question.score <- (tour$event - tour$q)^2
tour %>% 
  group_by(tournament, contestant, sigma) %>% 
  summarise(score=sum(question.score)) -> tournament.table1
tournament.table2 <- tournament.table1[order(tournament.table1$tournament, tournament.table1$score),]
tournament.table2$win <- rep(c(1,rep(0,nC-1)),N)
tournament.table2 %>% group_by(contestant, sigma) %>% summarise(som=sum(win)) -> endscore
ggplot(data=endscore, aes(x=contestant, y=som)) + 
  geom_bar(stat="identity") +
  xlim(0,nC) +
  labs(title = "Tournament wins for each contestant\n uniform model in [p-sigma,p+sigma]", 
       subtitle = paste(nC,"forecasters","taking part in",N,"tournaments"),
       x = "contestant", 
       y = paste("number of wins in", N,"tournaments")) +
  JT.theme
@

\begin{marginfigure}[-2cm]
\centering
\includegraphics[width=200pt, height=200pt]{Tour-fiftyTRJ}
\caption{50 contestants}
\label{fig:fiftyTRJ}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\newpage
\subsection{Groups without Perfect Forecasters}
However: eliminating the \emph{Perfect Forecasters} and working only with \emph{Flawed Forecasters} gets us back on track.
% 50 flawed contestants
<<label=fiftyflawedTRJ,fig=TRUE,include=FALSE, echo=FALSE>>=
set.seed(2018) # setting the random number generator
# set up data frame with known probabilities p and 
# randomly chosen probabilities q in range [p-sigma,p+sigma]
nC <- 50 # number of contestants
sigma.min <- 0.15
sigma.max <- 0.45
tour <- data.frame(tournament = rep(seq(1:N), each=n*nC),
                   contestant = rep(rep(seq(1:nC), each=n), N),
                   question = rep(seq(1:n), N*nC),
                   p = rep(prob.event, N*nC*n/10),
                   event = 0,
                   q = 0)
tour$sigma <- sigma.min + (sigma.max - sigma.min)*(tour$contestant - 1)/(nC - 1)
tour$lower.limit <- ifelse(tour$p - tour$sigma < 0, 0, tour$p - tour$sigma)
tour$upper.limit <- ifelse(tour$p + tour$sigma > 1, 1, tour$p + tour$sigma)
if(Aldous==TRUE) { 
        tour$q <- ifelse(runif(n*nC*N,tour$lower.limit,tour$upper.limit)<(tour$lower.limit+tour$upper.limit)/2, 
                              tour$lower.limit, 
                              tour$upper.limit)
} else {
        tour$q <- runif(n*nC*N, tour$lower.limit, tour$upper.limit)
}
for (i in (1:N)) {
 tour$event[((i-1)*n*nC+ 1):(i*n*nC)] <- rep(rbinom(n,1,prob.event),nC)
}
tour$question.score <- (tour$event - tour$q)^2
tour %>% 
  group_by(tournament, contestant, sigma) %>% 
  summarise(score=sum(question.score)) -> tournament.table1
tournament.table2 <- tournament.table1[order(tournament.table1$tournament, tournament.table1$score),]
tournament.table2$win <- rep(c(1,rep(0,nC-1)),N)
tournament.table2 %>% group_by(contestant, sigma) %>% summarise(som=sum(win)) -> endscore
ggplot(data=endscore, aes(x=contestant, y=som)) + 
  geom_bar(stat="identity") +
  xlim(0,nC) +
  labs(title = "Tournament wins for each contestant\n uniform model in [p-sigma,p+sigma]", 
       subtitle = paste(nC,"forecasters","taking part in",N,"tournaments"),
       x = "contestant", 
       y = paste("number of wins in", N,"tournaments")) +
  JT.theme
@

\begin{marginfigure}
\centering
\includegraphics[width=200pt, height=200pt]{Tour-fiftyflawedTRJ}
\caption{50 flawed contestants}
\label{fig:fiftyflawedTRJ}
\setfloatalignment{b}% forces caption to be bottom-aligned
\end{marginfigure}

\newpage
\textbf{Thanks} \\
\medskip
R Core Team (2018). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.
\medskip
<<>>=
sessionInfo()
@

\end{document}